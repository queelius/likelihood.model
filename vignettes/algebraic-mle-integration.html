<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Integration with algebraic.mle and algebraic.dist</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Integration with algebraic.mle and
algebraic.dist</h1>


<div id="TOC">
<ul>
<li><a href="#the-three-package-ecosystem" id="toc-the-three-package-ecosystem">The Three-Package
Ecosystem</a></li>
<li><a href="#basic-interface-params-nparams-observed_fim" id="toc-basic-interface-params-nparams-observed_fim">Basic Interface:
<code>params</code>, <code>nparams</code>,
<code>observed_fim</code></a></li>
<li><a href="#parameter-transformations-via-rmap" id="toc-parameter-transformations-via-rmap">Parameter Transformations
via <code>rmap</code></a></li>
<li><a href="#marginal-distributions" id="toc-marginal-distributions">Marginal Distributions</a></li>
<li><a href="#monte-carlo-expectations" id="toc-monte-carlo-expectations">Monte Carlo Expectations</a></li>
<li><a href="#mean-squared-error" id="toc-mean-squared-error">Mean
Squared Error</a></li>
<li><a href="#bootstrap-integration" id="toc-bootstrap-integration">Bootstrap Integration</a></li>
<li><a href="#using-algebraic.dist-distributions" id="toc-using-algebraic.dist-distributions">Using
<code>algebraic.dist</code> Distributions</a></li>
<li><a href="#summary" id="toc-summary">Summary</a></li>
</ul>
</div>

<div id="the-three-package-ecosystem" class="section level2">
<h2>The Three-Package Ecosystem</h2>
<p>The <code>likelihood.model</code> package is part of an ecosystem of
three interoperable packages:</p>
<ul>
<li><strong><code>algebraic.dist</code></strong> — probability
distribution objects with a common interface (<code>params</code>,
<code>sampler</code>, <code>expectation</code>, etc.)</li>
<li><strong><code>algebraic.mle</code></strong> — maximum likelihood
estimation infrastructure, defining the <code>mle</code> class and
generics like <code>params</code>, <code>nparams</code>,
<code>observed_fim</code>, <code>rmap</code>, <code>marginal</code>, and
<code>expectation</code></li>
<li><strong><code>likelihood.model</code></strong> — likelihood model
specification and Fisherian inference</li>
</ul>
<p>When you fit a model with <code>likelihood.model</code>, the result
is a <code>fisher_mle</code> object that inherits from
<code>algebraic.mle::mle</code>. This means all of the
<code>algebraic.mle</code> generics work on it directly:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(likelihood.model)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(algebraic.mle)</span></code></pre></div>
</div>
<div id="basic-interface-params-nparams-observed_fim" class="section level2">
<h2>Basic Interface: <code>params</code>, <code>nparams</code>,
<code>observed_fim</code></h2>
<p>Let’s fit a Weibull model and explore the MLE through the
<code>algebraic.mle</code> interface:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>true_shape <span class="ot">&lt;-</span> <span class="fl">2.5</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>true_scale <span class="ot">&lt;-</span> <span class="fl">3.0</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">rweibull</span>(n, <span class="at">shape =</span> true_shape, <span class="at">scale =</span> true_scale))</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">weibull_uncensored</span>(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>mle_result <span class="ot">&lt;-</span> <span class="fu">fit</span>(model)(df, <span class="at">par =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co"># algebraic.mle generics — these work because fisher_mle inherits from mle</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="fu">params</span>(mle_result)</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="co">#&gt; [1] 2.289 2.961</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="fu">nparams</span>(mle_result)</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="co">#&gt; [1] 2</span></span></code></pre></div>
<p>The MLE estimates (roughly 2.29 for shape, 2.96 for scale) are close
to the true values (2.5, 3.0), demonstrating good recovery with <span class="math inline">\(n = 200\)</span> observations. The
<code>params()</code> and <code>nparams()</code> generics work
identically to how they work on native <code>algebraic.mle::mle</code>
objects — because <code>fisher_mle</code> inherits from that class, the
entire <code>algebraic.mle</code> interface is available without any
adapter code.</p>
<p>The <code>observed_fim()</code> function returns the observed Fisher
information matrix, computed as the negative Hessian of the
log-likelihood at the MLE:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">observed_fim</span>(mle_result)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co">#&gt;        [,1]   [,2]</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co">#&gt; [1,]  76.00 -30.96</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co">#&gt; [2,] -30.96 119.58</span></span></code></pre></div>
<p>The off-diagonal element (roughly <span class="math inline">\(-31\)</span>) reveals a negative correlation
between the shape and scale estimators — when one is overestimated, the
other tends to be underestimated. This is a common feature of
location-scale families: the parameters trade off against each other in
explaining the data.</p>
<p>This should be positive definite at the MLE — we can verify:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">eigen</span>(<span class="fu">observed_fim</span>(mle_result))<span class="sc">$</span>values</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co">#&gt; [1] 135.65  59.94</span></span></code></pre></div>
<p>Both eigenvalues are positive, confirming the MLE sits at a proper
maximum of the log-likelihood. The ratio of the eigenvalues (roughly
2.3:1) tells us the likelihood surface is moderately elongated — the
curvature is steeper in one direction than the other, meaning one linear
combination of the parameters is better determined than the other.</p>
<p>For comparison, <code>vcov()</code> is the inverse of the observed
FIM:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">vcov</span>(mle_result)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="co">#&gt;          [,1]     [,2]</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co">#&gt; [1,] 0.014708 0.003807</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co">#&gt; [2,] 0.003807 0.009348</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="fu">solve</span>(<span class="fu">observed_fim</span>(mle_result))</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co">#&gt;          [,1]     [,2]</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">#&gt; [1,] 0.014708 0.003807</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co">#&gt; [2,] 0.003807 0.009348</span></span></code></pre></div>
<p>The numerical equality confirms that <code>vcov()</code> is computed
as <code>solve(observed_fim())</code>, the classical relationship <span class="math inline">\(\widehat{\text{Var}}(\hat\theta) =
I(\hat\theta)^{-1}\)</span>. This is worth noting because the two
matrices carry different conceptual meaning — the FIM measures
<em>information content</em> (how much the data tell us about the
parameters), while the variance-covariance matrix measures
<em>estimation uncertainty</em> — yet they are matrix inverses of each
other.</p>
</div>
<div id="parameter-transformations-via-rmap" class="section level2">
<h2>Parameter Transformations via <code>rmap</code></h2>
<p>One powerful feature of <code>algebraic.mle</code> is the
<code>rmap()</code> function, which transforms MLE parameters using the
delta method. This propagates uncertainty through nonlinear
transformations.</p>
<p>For a Weibull distribution with shape <span class="math inline">\(k\)</span> and scale <span class="math inline">\(\lambda\)</span>, the mean lifetime is: <span class="math display">\[E[T] = \lambda \, \Gamma\!\left(1 +
\tfrac{1}{k}\right)\]</span></p>
<p>We can transform our (shape, scale) MLE to get an MLE for the mean
lifetime:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Transform Weibull (shape, scale) -&gt; mean lifetime</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>mean_life_mle <span class="ot">&lt;-</span> <span class="fu">rmap</span>(mle_result, <span class="cf">function</span>(p) {</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>  <span class="fu">c</span>(<span class="at">mean_lifetime =</span> p[<span class="dv">2</span>] <span class="sc">*</span> <span class="fu">gamma</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="dv">1</span> <span class="sc">/</span> p[<span class="dv">1</span>]))</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>})</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="fu">params</span>(mean_life_mle)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">#&gt; mean_lifetime </span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">#&gt;         2.623</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="fu">se</span>(mean_life_mle)</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="co">#&gt; [1] 0.08492</span></span></code></pre></div>
<p>The delta method gives an estimated mean lifetime of roughly 2.62
with an SE of about 0.085. This propagates the joint uncertainty in
(shape, scale) through the nonlinear <span class="math inline">\(\Gamma\)</span>-function transformation —
something not possible with simple error propagation formulas that treat
parameters independently. The off-diagonal covariance we saw earlier is
correctly accounted for.</p>
<p>Compare to the true mean lifetime:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>true_mean <span class="ot">&lt;-</span> true_scale <span class="sc">*</span> <span class="fu">gamma</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="dv">1</span> <span class="sc">/</span> true_shape)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;True mean lifetime:&quot;</span>, true_mean, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co">#&gt; True mean lifetime: 2.662</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Estimated mean lifetime:&quot;</span>, <span class="fu">params</span>(mean_life_mle), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co">#&gt; Estimated mean lifetime: 2.623</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;95% CI:&quot;</span>, <span class="fu">confint</span>(mean_life_mle), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="co">#&gt; 95% CI: 2.456 2.789</span></span></code></pre></div>
<p>The true mean lifetime (about 2.66) falls within the 95% confidence
interval, as expected. The estimate slightly undershoots because our
shape estimate (roughly 2.29) is below the true 2.5 — and the mean
lifetime <span class="math inline">\(\lambda\,\Gamma(1 + 1/k)\)</span>
is sensitive to shape through the <span class="math inline">\(\Gamma\)</span> function.</p>
<p>We can also transform to multiple derived quantities at once:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Derive mean, variance, and median of the Weibull distribution</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>derived_mle <span class="ot">&lt;-</span> <span class="fu">rmap</span>(mle_result, <span class="cf">function</span>(p) {</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>  k <span class="ot">&lt;-</span> p[<span class="dv">1</span>]; lam <span class="ot">&lt;-</span> p[<span class="dv">2</span>]</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>    <span class="at">mean   =</span> lam <span class="sc">*</span> <span class="fu">gamma</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>k),</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>    <span class="at">var    =</span> lam<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> (<span class="fu">gamma</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="dv">2</span><span class="sc">/</span>k) <span class="sc">-</span> <span class="fu">gamma</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>k)<span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>    <span class="at">median =</span> lam <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span>)<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span>k)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>  )</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>})</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="fu">params</span>(derived_mle)</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="co">#&gt;   mean    var median </span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="co">#&gt;  2.623  1.475  2.523</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="fu">se</span>(derived_mle)</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a><span class="co">#&gt; [1] 0.08758 0.14780 0.09227</span></span></code></pre></div>
<p>Notice that the variance has the largest SE (roughly 0.15) relative
to its estimate — second moments are inherently harder to estimate than
first moments like the mean and median. This is a general phenomenon:
higher-order moments amplify estimation uncertainty because they involve
larger powers of the data.</p>
</div>
<div id="marginal-distributions" class="section level2">
<h2>Marginal Distributions</h2>
<p>The <code>marginal()</code> function extracts the sampling
distribution of a single parameter from a multivariate MLE:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Marginal for shape parameter</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>shape_mle <span class="ot">&lt;-</span> <span class="fu">marginal</span>(mle_result, <span class="dv">1</span>)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="fu">params</span>(shape_mle)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="co">#&gt; [1] 2.289</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="fu">se</span>(shape_mle)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co">#&gt; [1] 0.1213</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="fu">confint</span>(shape_mle)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="co">#&gt;         2.5% 97.5%</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="co">#&gt; param1 2.051 2.527</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a><span class="co"># Marginal for scale parameter</span></span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>scale_mle <span class="ot">&lt;-</span> <span class="fu">marginal</span>(mle_result, <span class="dv">2</span>)</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a><span class="fu">params</span>(scale_mle)</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a><span class="co">#&gt; [1] 2.961</span></span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a><span class="fu">se</span>(scale_mle)</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a><span class="co">#&gt; [1] 0.09668</span></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a><span class="fu">confint</span>(scale_mle)</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a><span class="co">#&gt;         2.5% 97.5%</span></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a><span class="co">#&gt; param1 2.771  3.15</span></span></code></pre></div>
<p>Both 95% CIs contain the true values (shape: 2.5; scale: 3.0). The
marginal distributions are useful for reporting single-parameter
uncertainties, though they discard the correlation between parameters.
For inference that respects the joint structure — such as a confidence
region for (shape, scale) simultaneously — you would use the full
multivariate MLE object.</p>
</div>
<div id="monte-carlo-expectations" class="section level2">
<h2>Monte Carlo Expectations</h2>
<p>The <code>expectation()</code> function computes Monte Carlo
expectations over the MLE’s asymptotic sampling distribution. This is
useful for computing quantities that are nonlinear functions of the
parameters.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co"># E[shape^2] under the asymptotic distribution</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>e_shape_sq <span class="ot">&lt;-</span> <span class="fu">expectation</span>(mle_result, <span class="cf">function</span>(p) p[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>                          <span class="at">control =</span> <span class="fu">list</span>(<span class="at">n =</span> <span class="dv">10000</span><span class="dt">L</span>))</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;E[shape^2]:&quot;</span>, e_shape_sq, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co">#&gt; E[shape^2]: 5.254</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;shape^2 at MLE:&quot;</span>, <span class="fu">params</span>(mle_result)[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span>, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co">#&gt; shape^2 at MLE: 5.24</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a><span class="co"># Probability that shape &gt; 2 (under asymptotic distribution)</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>pr_shape_gt_2 <span class="ot">&lt;-</span> <span class="fu">expectation</span>(mle_result, <span class="cf">function</span>(p) <span class="fu">as.numeric</span>(p[<span class="dv">1</span>] <span class="sc">&gt;</span> <span class="dv">2</span>),</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>                             <span class="at">control =</span> <span class="fu">list</span>(<span class="at">n =</span> <span class="dv">10000</span><span class="dt">L</span>))</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;P(shape &gt; 2):&quot;</span>, pr_shape_gt_2, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="co">#&gt; P(shape &gt; 2): 0.9917</span></span></code></pre></div>
<p><span class="math inline">\(E[\hat k^2] \approx 5.25\)</span> versus
the plug-in value <span class="math inline">\(\hat k^2 \approx
5.24\)</span>. The small difference (roughly 0.01) equals <span class="math inline">\(\text{Var}(\hat k)\)</span>, as expected from the
identity <span class="math inline">\(E[X^2] = \text{Var}(X) +
(E[X])^2\)</span>. The probability <span class="math inline">\(P(\hat k
&gt; 2) \approx 0.99\)</span> gives strong evidence that the true shape
exceeds 2, which would be useful in practice to confirm the hazard rate
is increasing (a Weibull shape <span class="math inline">\(&gt;
1\)</span> implies increasing hazard; <span class="math inline">\(&gt;
2\)</span> implies the hazard rate itself is accelerating).</p>
</div>
<div id="mean-squared-error" class="section level2">
<h2>Mean Squared Error</h2>
<p>Under standard MLE asymptotics, bias is zero and MSE equals the
variance-covariance matrix:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">mse</span>(mle_result)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="co">#&gt;          [,1]     [,2]</span></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co">#&gt; [1,] 0.014708 0.003807</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co">#&gt; [2,] 0.003807 0.009348</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="fu">all.equal</span>(<span class="fu">mse</span>(mle_result), <span class="fu">vcov</span>(mle_result))</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span></code></pre></div>
<p>The <code>TRUE</code> result confirms that MSE = Vcov under the
assumption of zero asymptotic bias. In finite samples (especially small
<span class="math inline">\(n\)</span>), a bootstrap-based
<code>mse()</code> can differ from <code>vcov()</code> because the bias
component <span class="math inline">\(\text{bias}^2\)</span> is no
longer negligible.</p>
</div>
<div id="bootstrap-integration" class="section level2">
<h2>Bootstrap Integration</h2>
<p>The <code>sampler()</code> generic creates a bootstrap sampling
distribution. The resulting <code>fisher_boot</code> object also
satisfies the <code>mle</code> interface:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>boot_sampler <span class="ot">&lt;-</span> <span class="fu">sampler</span>(model, <span class="at">df =</span> df, <span class="at">par =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>boot_result <span class="ot">&lt;-</span> <span class="fu">boot_sampler</span>(<span class="at">n =</span> <span class="dv">200</span>)</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="co"># Same algebraic.mle generics work</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="fu">params</span>(boot_result)</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a><span class="co">#&gt; [1] 2.289 2.961</span></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a><span class="fu">nparams</span>(boot_result)</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a><span class="co">#&gt; [1] 2</span></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a><span class="fu">se</span>(boot_result)</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a><span class="co">#&gt; [1] 0.11575 0.09085</span></span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a><span class="fu">bias</span>(boot_result)</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a><span class="co">#&gt; [1]  0.006446 -0.005939</span></span></code></pre></div>
<p>The bootstrap bias (roughly 0.006 for shape, <span class="math inline">\(-0.006\)</span> for scale) is negligible compared
to the standard errors, consistent with the MLE being asymptotically
unbiased. The bootstrap SEs are slightly smaller than the asymptotic SEs
— both methods agree well with <span class="math inline">\(n =
200\)</span> observations, but they need not agree exactly because they
estimate the sampling variability in different ways (resampling vs the
curvature of the log-likelihood).</p>
<p>The bootstrap provides an alternative (non-parametric) estimate of
the sampling distribution. Compare bootstrap and asymptotic confidence
intervals:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Asymptotic 95% CI:</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="co">#&gt; Asymptotic 95% CI:</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="fu">confint</span>(mle_result)</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co">#&gt;       2.5% 97.5%</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co">#&gt; [1,] 2.051 2.527</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co">#&gt; [2,] 2.771 3.150</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Bootstrap percentile 95% CI:</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="co">#&gt; Bootstrap percentile 95% CI:</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a><span class="fu">confint</span>(boot_result, <span class="at">type =</span> <span class="st">&quot;perc&quot;</span>)</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a><span class="co">#&gt;       2.5% 97.5%</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a><span class="co">#&gt; [1,] 2.069 2.577</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a><span class="co">#&gt; [2,] 2.778 3.130</span></span></code></pre></div>
<p>The asymptotic and bootstrap CIs are close but not identical. The
bootstrap percentile intervals are slightly asymmetric (the upper tails
extend a bit further), capturing the mild skewness in the finite-sample
distribution that the symmetric Wald intervals miss. For well-behaved
likelihoods with moderate <span class="math inline">\(n\)</span>, the
practical difference is small — but in small-sample or non-regular
problems, the bootstrap can be substantially more accurate.</p>
</div>
<div id="using-algebraic.dist-distributions" class="section level2">
<h2>Using <code>algebraic.dist</code> Distributions</h2>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">library</span>(algebraic.dist)</span></code></pre></div>
<p>The <code>algebraic.dist</code> package provides distribution objects
with a consistent interface. We can compare the MLE’s asymptotic
sampling distribution to theoretical distribution objects.</p>
<p>For example, the MLE of an exponential rate parameter <span class="math inline">\(\hat\lambda\)</span> is asymptotically normal with
variance <span class="math inline">\(\lambda^2/n\)</span>. We can create
this theoretical distribution:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>lambda_true <span class="ot">&lt;-</span> <span class="fl">2.0</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>n_exp <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>df_exp <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">t =</span> <span class="fu">rexp</span>(n_exp, <span class="at">rate =</span> lambda_true))</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>model_exp <span class="ot">&lt;-</span> <span class="fu">exponential_lifetime</span>(<span class="st">&quot;t&quot;</span>)</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>mle_exp <span class="ot">&lt;-</span> <span class="fu">fit</span>(model_exp)(df_exp)</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;MLE:&quot;</span>, <span class="fu">params</span>(mle_exp), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a><span class="co">#&gt; MLE: 1.727</span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;SE:&quot;</span>, <span class="fu">se</span>(mle_exp), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a><span class="co">#&gt; SE: 0.1221</span></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a><span class="co"># Theoretical asymptotic distribution of the MLE</span></span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a>asymp_var <span class="ot">&lt;-</span> lambda_true<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> n_exp</span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a>asymp_dist <span class="ot">&lt;-</span> <span class="fu">normal</span>(<span class="at">mu =</span> lambda_true, <span class="at">var =</span> asymp_var)</span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Theoretical asymptotic distribution:</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a><span class="co">#&gt; Theoretical asymptotic distribution:</span></span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;  Mean:&quot;</span>, <span class="fu">params</span>(asymp_dist)[<span class="dv">1</span>], <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb15-21"><a href="#cb15-21" tabindex="-1"></a><span class="co">#&gt;   Mean: 2</span></span>
<span id="cb15-22"><a href="#cb15-22" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;  Variance:&quot;</span>, <span class="fu">params</span>(asymp_dist)[<span class="dv">2</span>], <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb15-23"><a href="#cb15-23" tabindex="-1"></a><span class="co">#&gt;   Variance: 0.02</span></span>
<span id="cb15-24"><a href="#cb15-24" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" tabindex="-1"></a><span class="co"># Compare: sample from the MLE&#39;s estimated distribution</span></span>
<span id="cb15-26"><a href="#cb15-26" tabindex="-1"></a>mle_sampler <span class="ot">&lt;-</span> <span class="fu">sampler</span>(mle_exp)</span>
<span id="cb15-27"><a href="#cb15-27" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb15-28"><a href="#cb15-28" tabindex="-1"></a>mle_samples <span class="ot">&lt;-</span> <span class="fu">mle_sampler</span>(<span class="dv">5000</span>)</span>
<span id="cb15-29"><a href="#cb15-29" tabindex="-1"></a></span>
<span id="cb15-30"><a href="#cb15-30" tabindex="-1"></a><span class="co"># vs. sample from the theoretical distribution</span></span>
<span id="cb15-31"><a href="#cb15-31" tabindex="-1"></a>dist_sampler <span class="ot">&lt;-</span> <span class="fu">sampler</span>(asymp_dist)</span>
<span id="cb15-32"><a href="#cb15-32" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb15-33"><a href="#cb15-33" tabindex="-1"></a>dist_samples <span class="ot">&lt;-</span> <span class="fu">dist_sampler</span>(<span class="dv">5000</span>)</span>
<span id="cb15-34"><a href="#cb15-34" tabindex="-1"></a></span>
<span id="cb15-35"><a href="#cb15-35" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">MLE sampler mean:&quot;</span>, <span class="fu">mean</span>(mle_samples), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb15-36"><a href="#cb15-36" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb15-37"><a href="#cb15-37" tabindex="-1"></a><span class="co">#&gt; MLE sampler mean: 1.727</span></span>
<span id="cb15-38"><a href="#cb15-38" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Theoretical sampler mean:&quot;</span>, <span class="fu">mean</span>(dist_samples), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb15-39"><a href="#cb15-39" tabindex="-1"></a><span class="co">#&gt; Theoretical sampler mean: 2</span></span>
<span id="cb15-40"><a href="#cb15-40" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;MLE sampler sd:&quot;</span>, <span class="fu">sd</span>(mle_samples), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb15-41"><a href="#cb15-41" tabindex="-1"></a><span class="co">#&gt; MLE sampler sd: 0.1254</span></span>
<span id="cb15-42"><a href="#cb15-42" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Theoretical sampler sd:&quot;</span>, <span class="fu">sd</span>(dist_samples), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb15-43"><a href="#cb15-43" tabindex="-1"></a><span class="co">#&gt; Theoretical sampler sd: 0.1452</span></span></code></pre></div>
<p>The MLE sampler is centered at <span class="math inline">\(\hat\lambda\)</span> (the estimate from our data),
while the theoretical distribution is centered at the true <span class="math inline">\(\lambda = 2.0\)</span>. The gap between these
centers reflects sampling variability — our particular data set yielded
a rate estimate somewhat different from the truth. The standard
deviations are comparable, with the MLE-based SE slightly smaller
because it uses the estimated (smaller) rate rather than the true rate
in the variance formula <span class="math inline">\(\lambda^2/n\)</span>.</p>
<p>Distribution objects from <code>algebraic.dist</code> also support
computing exact expectations via numerical integration, which we can
compare to our Monte Carlo estimates:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># Exact E[X^2] for the asymptotic distribution</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>exact_e_x2 <span class="ot">&lt;-</span> <span class="fu">expectation</span>(asymp_dist, <span class="cf">function</span>(x) x<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Exact E[lambda_hat^2]:&quot;</span>, exact_e_x2, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a><span class="co">#&gt; Exact E[lambda_hat^2]: 4.02</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="co"># Compare to Monte Carlo estimate from the MLE</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>mc_e_x2 <span class="ot">&lt;-</span> <span class="fu">expectation</span>(mle_exp, <span class="cf">function</span>(p) p[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>                        <span class="at">control =</span> <span class="fu">list</span>(<span class="at">n =</span> <span class="dv">50000</span><span class="dt">L</span>))</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Monte Carlo E[lambda_hat^2]:&quot;</span>, mc_e_x2, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a><span class="co">#&gt; Monte Carlo E[lambda_hat^2]: 2.998</span></span></code></pre></div>
<p>The exact <span class="math inline">\(E[\hat\lambda^2]\)</span> (from
the theoretical distribution centered at <span class="math inline">\(\lambda = 2\)</span>) differs noticeably from the
Monte Carlo estimate based on the MLE. This is not an error — they are
expectations under <em>different</em> distributions. The theoretical
distribution uses the true parameter, while the MLE-based distribution
is centered at <span class="math inline">\(\hat\lambda\)</span>. This
distinction is important in practice: the MLE-based quantities are what
you can compute from data alone, while the theoretical ones require
knowing the true parameter (which is usually unknown).</p>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>The <code>fisher_mle</code> objects returned by
<code>likelihood.model</code> are fully compatible with the
<code>algebraic.mle</code> interface:</p>
<table>
<colgroup>
<col width="23%" />
<col width="76%" />
</colgroup>
<thead>
<tr class="header">
<th>Generic</th>
<th>What it does on <code>fisher_mle</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>params()</code></td>
<td>Parameter estimates (same as <code>coef()</code>)</td>
</tr>
<tr class="even">
<td><code>nparams()</code></td>
<td>Number of parameters</td>
</tr>
<tr class="odd">
<td><code>se()</code></td>
<td>Standard errors</td>
</tr>
<tr class="even">
<td><code>vcov()</code></td>
<td>Variance-covariance matrix</td>
</tr>
<tr class="odd">
<td><code>observed_fim()</code></td>
<td>Observed Fisher information (<span class="math inline">\(-H\)</span>)</td>
</tr>
<tr class="even">
<td><code>bias()</code></td>
<td>Asymptotic bias (zero)</td>
</tr>
<tr class="odd">
<td><code>mse()</code></td>
<td>Mean squared error (equals <code>vcov</code> asymptotically)</td>
</tr>
<tr class="even">
<td><code>aic()</code></td>
<td>Akaike information criterion</td>
</tr>
<tr class="odd">
<td><code>confint()</code></td>
<td>Wald confidence intervals</td>
</tr>
<tr class="even">
<td><code>rmap()</code></td>
<td>Delta method parameter transformations</td>
</tr>
<tr class="odd">
<td><code>marginal()</code></td>
<td>Marginal sampling distributions</td>
</tr>
<tr class="even">
<td><code>expectation()</code></td>
<td>Monte Carlo expectations over sampling distribution</td>
</tr>
<tr class="odd">
<td><code>sampler()</code></td>
<td>Asymptotic or bootstrap sampling function</td>
</tr>
</tbody>
</table>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
